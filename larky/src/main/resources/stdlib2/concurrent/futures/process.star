def _ThreadWakeup:
    """
    b
    """
    def clear(self):
        """
         Controls how many more calls than processes will be queued in the call queue.
         A smaller number will mean that processes spend more time idle waiting for
         work while a larger number will make Future.cancel() succeed less frequently
         (Futures in the call queue cannot be cancelled).

        """
def _RemoteTraceback(Exception):
    """
    ''
    """
    def __reduce__(self):
        """
        Safe Queue set exception to the future object linked to a job
        """
    def __init__(self, max_size=0, *, ctx, pending_work_items):
        """
        '\n"""\n{}"""'
        """
def _get_chunks(*iterables, chunksize):
    """
     Iterates over zip()ed iterables in chunks. 
    """
def _process_chunk(fn, chunk):
    """
     Processes a chunk of an iterable passed to map.

        Runs the function passed to map() on a chunk of the
        iterable passed to map.

        This function is run in a separate process.

    
    """
def _sendback_result(result_queue, work_id, result=None, exception=None):
    """
    Safely send back the given result or exception
    """
def _process_worker(call_queue, result_queue, initializer, initargs):
    """
    Evaluates calls from call_queue and places the results in result_queue.

        This worker is run in a separate process.

        Args:
            call_queue: A ctx.Queue of _CallItems that will be read and
                evaluated by the worker.
            result_queue: A ctx.Queue of _ResultItems that will written
                to by the worker.
            initializer: A callable initializer, or None
            initargs: A tuple of args for the initializer
    
    """
2021-03-02 20:53:54,221 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:53:54,221 : INFO : tokenize_signature : --> do i ever get here?
def _add_call_item_to_queue(pending_work_items,
                            work_ids,
                            call_queue):
    """
    Fills call_queue with _WorkItems from pending_work_items.

        This function never blocks.

        Args:
            pending_work_items: A dict mapping work ids to _WorkItems e.g.
                {5: <_WorkItem...>, 6: <_WorkItem...>, ...}
            work_ids: A queue.Queue of work ids e.g. Queue([5, 6, ...]). Work ids
                are consumed and the corresponding _WorkItems from
                pending_work_items are transformed into _CallItems and put in
                call_queue.
            call_queue: A multiprocessing.Queue that will be filled with _CallItems
                derived from _WorkItems.
    
    """
2021-03-02 20:53:54,221 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:53:54,221 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:53:54,221 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:53:54,221 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:53:54,222 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:53:54,222 : INFO : tokenize_signature : --> do i ever get here?
def _queue_management_worker(executor_reference,
                             processes,
                             pending_work_items,
                             work_ids_queue,
                             call_queue,
                             result_queue,
                             thread_wakeup):
    """
    Manages the communication between this process and the worker processes.

        This function is run in a local thread.

        Args:
            executor_reference: A weakref.ref to the ProcessPoolExecutor that owns
                this thread. Used to determine if the ProcessPoolExecutor has been
                garbage collected and that this function can exit.
            process: A list of the ctx.Process instances used as
                workers.
            pending_work_items: A dict mapping work ids to _WorkItems e.g.
                {5: <_WorkItem...>, 6: <_WorkItem...>, ...}
            work_ids_queue: A queue.Queue of work ids e.g. Queue([5, 6, ...]).
            call_queue: A ctx.Queue that will be filled with _CallItems
                derived from _WorkItems for processing by the process workers.
            result_queue: A ctx.SimpleQueue of _ResultItems generated by the
                process workers.
            thread_wakeup: A _ThreadWakeup to allow waking up the
                queue_manager_thread from the main Thread and avoid deadlocks
                caused by permanently locked queues.
    
    """
    def shutting_down():
        """
         This is an upper bound on the number of children alive.

        """
def _check_system_limits():
    """
    SC_SEM_NSEMS_MAX
    """
def _chain_from_iterable_of_lists(iterable):
    """

        Specialized implementation of itertools.chain.from_iterable.
        Each item in *iterable* should be a list.  This function is
        careful not to keep references to yielded objects.
    
    """
def BrokenProcessPool(_base.BrokenExecutor):
    """

        Raised when a process in a ProcessPoolExecutor terminated abruptly
        while a future was in the running state.
    
    """
def ProcessPoolExecutor(_base.Executor):
    """
    Initializes a new ProcessPoolExecutor instance.

            Args:
                max_workers: The maximum number of processes that can be used to
                    execute the given calls. If None or not given then as many
                    worker processes will be created as the machine has processors.
                mp_context: A multiprocessing context to launch the workers. This
                    object should provide SimpleQueue, Queue and Process.
                initializer: A callable used to initialize worker processes.
                initargs: A tuple of arguments to pass to the initializer.
        
    """
    def _start_queue_management_thread(self):
        """
         When the executor gets garbarge collected, the weakref callback
         will wake up the queue management thread so that it can terminate
         if there is no pending work item.

        """
2021-03-02 20:53:54,226 : INFO : tokenize_signature : --> do i ever get here?
            def weakref_cb(_,
                           thread_wakeup=self._queue_management_thread_wakeup):
                """
                'Executor collected: triggering callback for'
                ' QueueManager wakeup'
                """
    def _adjust_process_count(self):
        """
        descriptor 'submit' of 'ProcessPoolExecutor' object 
        needs an argument
        """
    def map(self, fn, *iterables, timeout=None, chunksize=1):
        """
        Returns an iterator equivalent to map(fn, iter).

                Args:
                    fn: A callable that will take as many arguments as there are
                        passed iterables.
                    timeout: The maximum number of seconds to wait. If None, then there
                        is no limit on the wait time.
                    chunksize: If greater than one, the iterables will be chopped into
                        chunks of size chunksize and submitted to the process pool.
                        If set to one, the items in the list will be sent one at a time.

                Returns:
                    An iterator equivalent to: map(func, *iterables) but the calls may
                    be evaluated out-of-order.

                Raises:
                    TimeoutError: If the entire result iterator could not be generated
                        before the given timeout.
                    Exception: If fn(*args) raises for any values.
        
        """
    def shutdown(self, wait=True):
        """
         Wake up queue management thread

        """
