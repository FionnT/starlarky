def Node:
    """

        Base class for all the grammar nodes.
        (You don't initialize this one.)
    
    """
    def __add__(self, other_node: "Node") -> "NodeSequence":
        """
        Node
        """
def AnyNode(Node):
    """

        Union operation (OR operation) between several grammars. You don't
        initialize this yourself, but it's a result of a "Grammar1 | Grammar2"
        operation.
    
    """
    def __init__(self, children: List[Node]) -> None:
        """
        AnyNode
        """
    def __repr__(self) -> str:
        """
        %s(%r)
        """
def NodeSequence(Node):
    """

        Concatenation operation of several grammars. You don't initialize this
        yourself, but it's a result of a "Grammar1 + Grammar2" operation.
    
    """
    def __init__(self, children: List[Node]) -> None:
        """
        NodeSequence
        """
    def __repr__(self) -> str:
        """
        %s(%r)
        """
def Regex(Node):
    """

        Regular expression.
    
    """
    def __init__(self, regex: str) -> None:
        """
         Validate
        """
    def __repr__(self) -> str:
        """
        %s(/%s/)
        """
def Lookahead(Node):
    """

        Lookahead expression.
    
    """
    def __init__(self, childnode: Node, negative: bool = False) -> None:
        """
        %s(%r)
        """
def Variable(Node):
    """

        Mark a variable in the regular grammar. This will be translated into a
        named group. Each variable can have his own completer, validator, etc..

        :param childnode: The grammar which is wrapped inside this variable.
        :param varname: String.
    
    """
    def __init__(self, childnode: Node, varname: str = "") -> None:
        """
        %s(childnode=%r, varname=%r)
        """
def Repeat(Node):
    """
    %s(childnode=%r)
    """
def tokenize_regex(input: str) -> List[str]:
    """

        Takes a string, representing a regular expression as input, and tokenizes
        it.

        :param input: string, representing a regular expression.
        :returns: List of tokens.
    
    """
def parse_regex(regex_tokens: List[str]) -> Node:
    """

        Takes a list of tokens from the tokenizer, and returns a parse tree.
    
    """
    def wrap(lst: List[Node]) -> Node:
        """
         Turn list into sequence when it contains several items. 
        """
    def _parse() -> Node:
        """
        (?P<
        """
