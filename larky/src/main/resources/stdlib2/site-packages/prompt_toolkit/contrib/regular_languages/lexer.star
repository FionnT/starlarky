def GrammarLexer(Lexer):
    """

        Lexer which can be used for highlighting of fragments according to variables in the grammar.

        (It does not actual lexing of the string, but it exposes an API, compatible
        with the Pygments lexer class.)

        :param compiled_grammar: Grammar as returned by the `compile()` function.
        :param lexers: Dictionary mapping variable names of the regular grammar to
                       the lexers that should be used for this part. (This can
                       call other lexers recursively.) If you wish a part of the
                       grammar to just get one fragment, use a
                       `prompt_toolkit.lexers.SimpleLexer`.
    
    """
2021-03-02 20:51:42,194 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:51:42,194 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:51:42,194 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:51:42,194 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:51:42,195 : INFO : tokenize_signature : --> do i ever get here?
    def __init__(
        self,
        compiled_grammar: _CompiledGrammar,
        default_style: str = "",
        lexers: Optional[Dict[str, Lexer]] = None,
    ) -> None:
        """
         If we have a `Lexer` instance for this part of the input.
         Tokenize recursively and apply tokens.

        """
    def lex_document(self, document: Document) -> Callable[[int], StyleAndTextTuples]:
