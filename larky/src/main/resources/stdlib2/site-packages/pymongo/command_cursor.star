def CommandCursor(object):
    """
    A cursor / iterator over command cursors.
    """
2021-03-02 20:50:13,689 : INFO : tokenize_signature : --> do i ever get here?
2021-03-02 20:50:13,689 : INFO : tokenize_signature : --> do i ever get here?
    def __init__(self, collection, cursor_info, address, retrieved=0,
                 batch_size=0, max_await_time_ms=None, session=None,
                 explicit_session=False):
        """
        Create a new command cursor.

                The parameter 'retrieved' is unused.
        
        """
    def __del__(self):
        """
        Closes this cursor.
        
        """
    def __end_session(self, synchronous):
        """
        Explicitly close / kill this cursor.
        
        """
    def batch_size(self, batch_size):
        """
        Limits the number of documents returned in one batch. Each batch
                requires a round trip to the server. It can be adjusted to optimize
                performance and limit data transfer.

                .. note:: batch_size can not override MongoDB's internal limits on the
                   amount of data it will return to the client in a single batch (i.e
                   if you set batch size to 1,000,000,000, MongoDB will currently only
                   return 4-16MB of results per batch).

                Raises :exc:`TypeError` if `batch_size` is not an integer.
                Raises :exc:`ValueError` if `batch_size` is less than ``0``.

                :Parameters:
                  - `batch_size`: The size of each batch of results requested.
        
        """
    def _has_next(self):
        """
        Returns `True` if the cursor has documents remaining from the
                previous batch.
        """
    def _post_batch_resume_token(self):
        """
        Retrieve the postBatchResumeToken from the response to a
                changeStream aggregate or getMore.
        """
    def __send_message(self, operation):
        """
        Send a getmore message and handle the response.
        
        """
        def kill():
            """
             Don't send kill cursors to another server after a "not master
             error. It's completely pointless.

            """
2021-03-02 20:50:13,693 : INFO : tokenize_signature : --> do i ever get here?
    def _unpack_response(self, response, cursor_id, codec_options,
                         user_fields=None, legacy_response=False):
        """
        Refreshes the cursor with more data from the server.

                Returns the length of self.__data after refresh. Will exit early if
                self.__data is already non-empty. Raises OperationFailure when the
                cursor cannot be refreshed due to an error on the query.
        
        """
    def alive(self):
        """
        Does this cursor have the potential to return more data?

                Even if :attr:`alive` is ``True``, :meth:`next` can raise
                :exc:`StopIteration`. Best to use a for loop::

                    for doc in collection.aggregate(pipeline):
                        print(doc)

                .. note:: :attr:`alive` can be True while iterating a cursor from
                  a failed server. In this case :attr:`alive` will return False after
                  :meth:`next` fails to retrieve the next batch of results from the
                  server.
        
        """
    def cursor_id(self):
        """
        Returns the id of the cursor.
        """
    def address(self):
        """
        The (host, port) of the server used, or None.

                .. versionadded:: 3.0
        
        """
    def session(self):
        """
        The cursor's :class:`~pymongo.client_session.ClientSession`, or None.

                .. versionadded:: 3.6
        
        """
    def __iter__(self):
        """
        Advance the cursor.
        """
    def _try_next(self, get_more_allowed):
        """
        Advance the cursor blocking for at most one getMore command.
        """
    def __enter__(self):
        """
        Create a new cursor / iterator over raw batches of BSON data.

                Should not be called directly by application developers -
                see :meth:`~pymongo.collection.Collection.aggregate_raw_batches`
                instead.

                .. mongodoc:: cursors
        
        """
2021-03-02 20:50:13,695 : INFO : tokenize_signature : --> do i ever get here?
    def _unpack_response(self, response, cursor_id, codec_options,
                         user_fields=None, legacy_response=False):
        """
        Cannot call __getitem__ on RawBatchCursor
        """
